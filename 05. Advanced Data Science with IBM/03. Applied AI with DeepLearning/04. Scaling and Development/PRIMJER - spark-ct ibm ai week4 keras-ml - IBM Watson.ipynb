{"nbformat_minor": 1, "cells": [{"source": "# Assignment 4\n## Understaning scaling of linear algebra operations on Apache Spark using Apache SystemML\n\nIn this assignment we want you to understand how to scale linear algebra operations from a single machine to multiple machines, memory and CPU cores using Apache SystemML. Therefore we want you to understand how to migrate from a numpy program to a SystemML DML program. Don't worry. We will give you a lot of hints. Finally, you won't need this knowledge anyways if you are sticking to Keras only, but once you go beyond that point you'll be happy to see what's going on behind the scenes. As usual, we run some import statements:", "cell_type": "markdown", "metadata": {}}, {"source": "!pip install --upgrade systemml", "cell_type": "code", "metadata": {"scrolled": true}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Requirement already up-to-date: systemml in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages\nRequirement already up-to-date: pandas in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages (from systemml)\nRequirement already up-to-date: scipy>=0.15.1 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages (from systemml)\nRequirement already up-to-date: scikit-learn in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages (from systemml)\nRequirement already up-to-date: Pillow>=2.0.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages (from systemml)\nRequirement already up-to-date: numpy>=1.8.2 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages (from systemml)\nRequirement already up-to-date: python-dateutil>=2.5.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages (from pandas->systemml)\nRequirement already up-to-date: pytz>=2011k in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages (from pandas->systemml)\nRequirement already up-to-date: six>=1.5 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages (from python-dateutil>=2.5.0->pandas->systemml)\n"}], "execution_count": 1}, {"source": "'''\nimport pip\n \ntry:\n    __import__('pandas')\nexcept ImportError:\n    pip.main(['install', 'pandas']) \n    \ntry:\n    __import__('dateutil')\nexcept ImportError:\n    pip.main(['install', 'dateutil'])     \n    \ntry:\n    __import__('systemml')\nexcept ImportError:\n    pip.main(['install', 'systemml'])         \n'''", "cell_type": "code", "metadata": {"scrolled": false}, "outputs": [], "execution_count": null}, {"source": "#!pip uninstall python-dateutil\n#!pip install python-dateutil --upgrade\n'''\npip.main(['uninstall', 'python-dateutil']) \npip.main(['install', 'python-dateutil']) \n'''", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "'''\nfrom pandas.compat.numpy import dateutil\n'''", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "from systemml import MLContext, dml\nimport numpy as np\nimport time", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stderr", "text": "/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/pandas/_libs/__init__.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  from .tslib import iNaT, NaT, Timestamp, Timedelta, OutOfBoundsDatetime\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/pandas/__init__.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  from pandas._libs import (hashtable as _hashtable,\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/pandas/core/dtypes/common.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  from pandas._libs import algos, lib\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/pandas/core/util/hashing.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  from pandas._libs import hashing, tslib\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/pandas/core/indexes/base.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  from pandas._libs import (lib, index as libindex, tslib as libts,\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/pandas/tseries/offsets.py:21: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  import pandas._libs.tslibs.offsets as liboffsets\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/pandas/core/ops.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  from pandas._libs import algos as libalgos, ops as libops\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/pandas/core/indexes/interval.py:32: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  from pandas._libs.interval import (\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/pandas/core/internals.py:14: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  from pandas._libs import internals as libinternals\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/pandas/core/sparse/array.py:33: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  import pandas._libs.sparse as splib\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/pandas/core/window.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  import pandas._libs.window as _window\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/pandas/core/groupby/groupby.py:68: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  from pandas._libs import (lib, reduction,\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/pandas/core/reshape/reshape.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  from pandas._libs import algos as _algos, reshape as _reshape\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/pandas/io/parsers.py:45: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  import pandas._libs.parsers as parsers\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/pandas/io/pytables.py:50: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  from pandas._libs import algos, lib, writers as libwriters\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/scipy/sparse/lil.py:19: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  from . import _csparsetools\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:165: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  from ._shortest_path import shortest_path, floyd_warshall, dijkstra,\\\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_validation.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  from ._tools import csgraph_to_dense, csgraph_from_dense,\\\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:167: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  from ._traversal import breadth_first_order, depth_first_order, \\\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:169: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  from ._min_spanning_tree import minimum_spanning_tree\n/gpfs/fs01/user/s0f2-ba03446bdf62cc-bd5847e99873/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:170: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  from ._reordering import reverse_cuthill_mckee, maximum_bipartite_matching, \\\n"}], "execution_count": 2}, {"source": "Then we create an MLContext to interface with Apache SystemML. Note that we pass a SparkSession object as parameter so SystemML now knows how to talk to the Apache Spark cluster", "cell_type": "markdown", "metadata": {}}, {"source": "ml = MLContext(spark)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 3}, {"source": "Now we create some large random matrices to have numpy and SystemML crunch on it", "cell_type": "markdown", "metadata": {}}, {"source": "u = np.random.rand(1000,10000)\ns = np.random.rand(10000,1000)\nw = np.random.rand(1000,1000)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 4}, {"source": "Now we implement a short one-liner to define a very simple linear algebra operation\n\nIn case you are not familiar with matrix-matrix multiplication: https://en.wikipedia.org/wiki/Matrix_multiplication\n\nsum(U' * (W . (U * S)))\n\n\n| Legend        |            |   \n| ------------- |-------------| \n| '      | transpose of a matrix | \n| * | matrix-matrix multiplication      |  \n| . | scalar multiplication      |   \n\n", "cell_type": "markdown", "metadata": {}}, {"source": "start = time.time()\nres = np.sum(u.T.dot(w * u.dot(s)))\nprint time.time()-start", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "0.197705030441\n"}], "execution_count": 5}, {"source": "As you can see this executes perfectly fine. Note that this is even a very efficient execution because numpy uses a C/C++ backend which is known for it's performance. But what happens if U, S or W get such big that the available main memory cannot cope with it? Let's give it a try:", "cell_type": "markdown", "metadata": {}}, {"source": "'''\nu = np.random.rand(10000,100000)\ns = np.random.rand(100000,10000)\nw = np.random.rand(10000,10000)\n'''", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 6}, {"source": "u = np.random.rand(10000,1100000)\ns = np.random.rand(1100000,10000)\nw = np.random.rand(10000,10000)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "error", "evalue": "", "traceback": ["\u001b[0;31m\u001b[0m", "\u001b[0;31mMemoryError\u001b[0mTraceback (most recent call last)", "\u001b[0;32m<ipython-input-12-b69efdec6149>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1100000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.rand\u001b[0;34m()\u001b[0m\n", "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.random_sample\u001b[0;34m()\u001b[0m\n", "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.cont0_array\u001b[0;34m()\u001b[0m\n", "\u001b[0;31mMemoryError\u001b[0m: "], "ename": "MemoryError"}], "execution_count": 12}, {"source": "After a short while you should see a memory error. This is because the operating system process was not able to allocate enough memory for storing the numpy array on the heap. Now it's time to re-implement the very same operations as DML in SystemML, and this is your task. Just replace all ###your_code_goes_here sections with proper code, please consider the following table which contains all DML syntax you need:\n\n| Syntax        |            |   \n| ------------- |-------------| \n| t(M)      | transpose of a matrix, where M is the matrix | \n| %*% | matrix-matrix multiplication      |  \n| * | scalar multiplication      |   \n\n## Task", "cell_type": "markdown", "metadata": {}}, {"source": "#res = np.sum(u.T.dot(w * u.dot(s)))\n#res = sum(###your_code_goes_here(U) %*% (W * (U ###your_code_goes_here S)))\nscript = \"\"\"\nres = sum( t(U) %*% (W * (U %*% S)))\n\"\"\"", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 13}, {"source": "To get consistent results we switch from a random matrix initialization to something deterministic", "cell_type": "markdown", "metadata": {}}, {"source": "u = np.arange(100000).reshape((100, 1000))\ns = np.arange(100000).reshape((1000, 100))\nw = np.arange(10000).reshape((100, 100))", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 14}, {"source": "prog = dml(script).input('U', u).input('S', s).input('W', w).output('res')\nres = ml.execute(prog).get('res')\nprint res", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "SystemML Statistics:\nTotal execution time:\t\t0.029 sec.\nNumber of executed Spark inst:\t3.\n\n\n1.25260525922e+28\n"}], "execution_count": 15}, {"source": "If everything runs fine you should get *1.25260525922e+28* as result. Feel free to submit your DML script to the grader now!\n\n### Submission", "cell_type": "markdown", "metadata": {}}, {"source": "!rm -f rklib.py\n!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/coursera/ai/rklib.py", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "--2018-07-24 11:26:32--  https://raw.githubusercontent.com/romeokienzler/developerWorks/master/coursera/ai/rklib.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2029 (2.0K) [text/plain]\nSaving to: \u2018rklib.py\u2019\n\n100%[======================================>] 2,029       --.-K/s   in 0s      \n\n2018-07-24 11:26:32 (15.6 MB/s) - \u2018rklib.py\u2019 saved [2029/2029]\n\n"}], "execution_count": 16}, {"source": "from rklib import submit\nkey = \"esRk7vn-Eeej-BLTuYzd0g\"\npart = \"fUxc8\"\n\nemail = \"roman.kazinnik@gmail.com\" #\"###_YOUR_CODE_GOES_HERE_###\"\nsecret = \"FmeLQKjwkiWKgqC2\" #\"###_YOUR_CODE_GOES_HERE_###\"\nsubmit(email, secret, key, part, [part], script)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Something went wrong, please have a look at the reponse of the grader\n-------------------------\n{\"errorCode\":\"78kj3h8h6\"}\n-------------------------\n"}], "execution_count": 17}, {"source": "", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 2 with Spark 2.1", "name": "python2-spark21", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.14", "name": "python", "pygments_lexer": "ipython2", "file_extension": ".py", "codemirror_mode": {"version": 2, "name": "ipython"}}}, "nbformat": 4}